{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 18:16:15.155871: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-19 18:16:15.155940: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "base_dir = '/home/fhd/projects/.DATASETS/HealthyControls/'\n",
    "ind_dir = os.path.join(base_dir,'C01')\n",
    "rec_path = os.path.join(ind_dir,'left_foot_trial_21.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single(img_path:str) -> np.memmap:\n",
    "    '''function that gets the path of a single record and returns the memmap array in shape of (36,20,:)'''\n",
    "    img = nib.load(img_path)\n",
    "    try:\n",
    "        data = img.get_fdata()\n",
    "        if not (data.shape[1] <20 or data.shape[0] < 35):\n",
    "            return img.get_fdata()[:35,:20,:]\n",
    "    except :\n",
    "        return None\n",
    "\n",
    "def read_all(all_path:list) -> pd.DataFrame:\n",
    "    '''get list of paths and returns of Y memmap of all records shape of (36,20,:)'''\n",
    "    Y = np.zeros((35,20,0)) # initiating Y \n",
    "    #reading all images\n",
    "    for path in all_path:\n",
    "        arr = read_single(os.path.join(ind_dir,path))\n",
    "        if type(arr)==np.memmap: Y = np.append(Y,arr,axis=2) #appending to Y\n",
    "    return Y\n",
    "    \n",
    "def preprocess(memmap:np.memmap) -> pd.DataFrame:\n",
    "    memmap = memmap.reshape(-1, memmap.shape[-1])\n",
    "    return pd.DataFrame(memmap).T\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(10,)))\n",
    "    model.add(tf.keras.layers.Dense(16,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(700,activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mse',metrics=['MeanSquaredError',])\n",
    "    return model\n",
    "\n",
    "def get_all_path( Left:bool =True, ex=None,inc=None) -> list:\n",
    "    '''if you want the left foot then put True else Flase, parameter ex excludes from output'''\n",
    "    all_path=[]\n",
    "    for folder in list(os.walk(base_dir)):\n",
    "        for filename in folder[2]:\n",
    "            if Left:\n",
    "                if 'left' in filename:\n",
    "                    all_path.append(os.path.join(folder[0],filename))\n",
    "            else:\n",
    "                if 'right' in filename:\n",
    "                    all_path.append(os.path.join(folder[0],filename))\n",
    "    if ex: all_path= list(filter(lambda x: ex not in x,all_path))\n",
    "    elif inc: all_path= list(filter(lambda x: inc in x,all_path))\n",
    "    return all_path\n",
    "\n",
    "def animate(result,name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from celluloid import Camera\n",
    "    fig = plt.figure(figsize=(3,6))\n",
    "    camera = Camera(fig)\n",
    "    for i in range (result.shape[2]):\n",
    "        plt.contourf(result[:,:,i],cmap='Reds')\n",
    "        plt.title(i)\n",
    "        if i:\n",
    "            camera.snap()\n",
    "    animation = camera.animate()\n",
    "    animation.save(os.path.join('output',name),fps=70)\n",
    "\n",
    "def convert_2dIndex_to_1d(index):\n",
    "    shape = (35,20)\n",
    "    x,y = index\n",
    "    _,Y = shape\n",
    "    return x*Y+y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making Y dataset\n",
    "all_path = get_all_path(ex='C31')\n",
    "Y = read_all(all_path)\n",
    "Y = preprocess(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making X dataset\n",
    "selected_nodes_2d =[(14,4),(11,4),(5,21),(3,22),(10,27),(7,32),(6,30),(9,32),(12,27),(6,23)]\n",
    "selected_nodes_1d = list(map(convert_2dIndex_to_1d,selected_nodes_2d))\n",
    "X = Y[selected_nodes_1d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size=0.2, shuffle =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:15:18.437979: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-19 14:15:18.438282: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-19 14:15:18.438588: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Fhd): /proc/driver/nvidia/version does not exist\n",
      "2022-01-19 14:15:18.443870: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:15:46.301999: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 916860000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2559/2559 [==============================] - ETA: 0s - loss: 19.3886 - mean_squared_error: 19.3886"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 14:16:00.559989: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 229219200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2559/2559 [==============================] - 15s 5ms/step - loss: 19.3886 - mean_squared_error: 19.3886 - val_loss: 19.4824 - val_mean_squared_error: 19.4824\n",
      "Epoch 2/5\n",
      "2559/2559 [==============================] - 12s 5ms/step - loss: 18.5366 - mean_squared_error: 18.5366 - val_loss: 19.6606 - val_mean_squared_error: 19.6606\n",
      "Epoch 3/5\n",
      "2559/2559 [==============================] - 12s 5ms/step - loss: 18.3731 - mean_squared_error: 18.3731 - val_loss: 19.7185 - val_mean_squared_error: 19.7185\n",
      "Epoch 4/5\n",
      "2559/2559 [==============================] - 12s 5ms/step - loss: 18.2188 - mean_squared_error: 18.2188 - val_loss: 20.0326 - val_mean_squared_error: 20.0326\n",
      "Epoch 5/5\n",
      "2559/2559 [==============================] - 12s 5ms/step - loss: 18.0897 - mean_squared_error: 18.0897 - val_loss: 19.6809 - val_mean_squared_error: 19.6809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb5f46241c0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=X_train, y=y_train, batch_size=64, epochs=5,\n",
    "    validation_split=0.2, validation_data=None, shuffle=True,\n",
    "    workers=2, use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making plot dataset\n",
    "test_path = get_all_path(inc='C31')\n",
    "Yplot = read_all(test_path)\n",
    "Yplot = preprocess(Yplot)\n",
    "Xplot = Yplot[selected_nodes_1d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(Xplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results.T\n",
    "result = result.reshape(35,20,result.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17448/2255546438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model-10input-first350-epoch5-fps70.gif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "animate(result[:,:,:350],'model-10input-first350-epoch5-fps70.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = get_all_path(inc='C31')\n",
    "Yplot = read_all(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "animate(Yplot[:,:,:350],'grandTruth-C031-first350-fps70.gif')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
